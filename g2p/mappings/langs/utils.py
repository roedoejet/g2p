"""

Utilities used by other classes

"""

import gzip
import json
from pathlib import Path
from typing import Any, Optional

import networkx
from networkx.algorithms.dag import ancestors, descendants

from g2p.log import LOGGER
from g2p.mappings import MAPPINGS_AVAILABLE, Mapping, MappingConfig
from g2p.mappings.langs import LANGS_DIR, LANGS_NETWORK, LANGS_NWORK_PATH, LANGS_PKL
from g2p.mappings.utils import MAPPING_TYPE, is_ipa

# panphon.distance.Distance() takes a long time to initialize, so...
# a) we don't want to load it if we don't need it, i.e., don't use a constant
# b) we don't want to load it more than once, i.e., don't use a local variable.
# Conclusion: use a singleton with lazy initialization
# Profiling results: calling is_panphon() the first time still costs 400ms, but subsequent
# calls cost .02ms each. With dst=panphone.distance.Distance() instead of
# dst=getPanphonDistanceSingleton(), the first call costs 400ms and subsequent calls
# cost 180ms each.

_PANPHON_DISTANCE_SINGLETON = None


def getPanphonDistanceSingleton():
    global _PANPHON_DISTANCE_SINGLETON
    if _PANPHON_DISTANCE_SINGLETON is None:
        import panphon.distance  # Expensive import, only do it when actually needed

        _PANPHON_DISTANCE_SINGLETON = panphon.distance.Distance()
    return _PANPHON_DISTANCE_SINGLETON


def check_ipa_known_segs(mappings_to_check=False) -> bool:
    """Check the given mappings, or all IPA mappings, for invalid IPA in the "out" fields

    Returns True iff not errors were found.
    """
    if not mappings_to_check:
        mappings_to_check = [x.out_lang for x in MAPPINGS_AVAILABLE]
    found_error = False

    for mapping in [x for x in MAPPINGS_AVAILABLE if x.out_lang in mappings_to_check]:
        if is_ipa(mapping.out_lang) and mapping.type == MAPPING_TYPE.mapping:
            reverse = mapping.reverse
            for rule in mapping.rules:
                output = rule.rule_input if reverse else rule.rule_output
                if not is_panphon(output):
                    LOGGER.warning(
                        f"Output '{rule.rule_output}' in rule {rule} in mapping between {mapping.in_lang} "
                        f"and {mapping.out_lang} is not recognized as valid IPA by panphon."
                    )
                    found_error = True
    if found_error:
        LOGGER.warning(
            "Please refer to https://github.com/dmort27/panphon for information about panphon."
        )
    return not found_error


_is_panphon_g_warning_printed = False
_is_panphon_colon_warning_printed = False


def is_panphon(string, display_warnings=False):
    # Deferred importing required here, because g2p.transducer also imports this file.
    # Such circular dependency is probably bad design, maybe a reviewer of this code will
    # have a better solution to recommend?
    import g2p.transducer

    dst = getPanphonDistanceSingleton()
    panphon_preprocessor = g2p.transducer.Transducer(
        Mapping.find_mapping_by_id("panphon_preprocessor")
    )
    preprocessed_string = panphon_preprocessor(string).output_string
    # Use a loop that prints the warnings on all strings that are not panphon, even though
    # logically this should not be necessary to calculate the answer.
    result = True
    for word in preprocessed_string.split():
        word_ipa_segs = dst.fm.ipa_segs(word)
        word_ipa = "".join(word_ipa_segs)
        if word != word_ipa:
            if not display_warnings:
                return False
            LOGGER.warning(
                f'String "{word}" is not identical to its IPA segmentation: {word_ipa_segs}'
            )
            global _is_panphon_g_warning_printed
            if "g" in word and not _is_panphon_g_warning_printed:
                LOGGER.warning(
                    "Common IPA gotcha: the ASCII 'g' character is not IPA, use 'ɡ' (\\u0261) instead."
                )
                _is_panphon_g_warning_printed = True
            global _is_panphon_colon_warning_printed
            if ":" in word and not _is_panphon_colon_warning_printed:
                LOGGER.warning(
                    "Common IPA gotcha: the ASCII ':' character is not IPA, use 'ː' (\\u02D0) instead."
                )
                _is_panphon_colon_warning_printed = True
            for c in word:
                if c not in word_ipa:
                    LOGGER.warning(
                        f"Character '{c}' (\\u{format(ord(c), '04x')}) in word '{word}' "
                        "was not recognized as IPA by panphon."
                    )
            result = False
    return result


_ARPABET_SET = None


def is_arpabet(string):
    global _ARPABET_SET
    if _ARPABET_SET is None:
        _ARPABET_SET = set(
            Mapping.find_mapping(in_lang="eng-ipa", out_lang="eng-arpabet").inventory(
                "out"
            )
        )
    # print(f"arpabet_set={_ARPABET_SET}")
    for sound in string.split():
        if sound not in _ARPABET_SET:
            return False
    return True


def cache_langs(
    dir_path: str = LANGS_DIR,
    langs_path: str = LANGS_PKL,
    network_path: str = LANGS_NWORK_PATH,
):
    """Read in all files and save as pickle.

    Args:
       dir_path: Path to scan for config-g2p.yaml files.  Default is the
                 installed g2p/mappings/langs directory.
       langs_path: Path to output langs.json.gz file.  Default is
                   the installed g2p/mappings/langs/langs.json.gz
       network_path: Path to output pickle file.  Default is the
                     installed g2p/mappings/langs/network.pkl.
    """
    langs = {}

    # Sort by language code
    paths = sorted(
        Path(dir_path).glob("./*/config-g2p.y*ml"), key=lambda x: x.parent.stem
    )
    mappings_legal_pairs = []
    if not paths:
        raise FileNotFoundError(
            f"There don't seem to be any valid mappings in {dir_path}"
        )
    for path in paths:
        code = path.parent.stem
        mapping_config = MappingConfig.load_mapping_config_from_path(path)
        # TODO: should put in some measure to prioritize non-generated
        # mappings and warn when they override
        mappings_legal_pairs.extend(
            [(mapping.in_lang, mapping.out_lang) for mapping in mapping_config.mappings]
        )
        langs[code] = mapping_config.export_to_dict()

    # Save as a Directional Graph
    lang_network = networkx.DiGraph()
    lang_network.add_edges_from(mappings_legal_pairs)
    write_json_gz(network_path, networkx.node_link_data(lang_network))
    write_json_gz(langs_path, langs)
    return langs


def write_json_gz(path: str, data: Any):
    with gzip.GzipFile(path, "wb", mtime=0) as zipfile:
        zipfile.write(
            json.dumps(
                data,
                separators=(",", ":"),
                ensure_ascii=False,
                sort_keys=True,
            ).encode("utf-8")
        )


def network_to_echart(outfile: Optional[str] = None, layout: bool = False):
    nodes = []
    no_nodes = len(LANGS_NETWORK.nodes)
    for node in LANGS_NETWORK.nodes:
        lang_name = node.split("-")[0]
        no_ancestors = len(ancestors(LANGS_NETWORK, node))
        no_descendants = len(descendants(LANGS_NETWORK, node))
        size = min(
            20,
            max(
                2, ((no_ancestors / no_nodes) * 100 + (no_descendants / no_nodes) * 100)
            ),
        )
        node = {"name": node, "symbolSize": size, "id": node, "category": lang_name}
        nodes.append(node)
    nodes.sort(key=lambda x: x["name"])
    edges = []
    for edge in LANGS_NETWORK.edges:
        edges.append({"source": edge[0], "target": edge[1]})
    if outfile:
        with open(
            outfile,
            "w",
            encoding="utf-8",
            newline="\n",
        ) as f:
            f.write(json.dumps({"nodes": nodes, "edges": edges}) + "\n")
        LOGGER.info("Wrote network nodes and edges to static file.")
    return nodes, edges
